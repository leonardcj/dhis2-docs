<?xml version='1.0' encoding='UTF-8'?>
<chapter version="5.0"
  xsi:schemaLocation="http://docbook.org/ns/docbook http://www.docbook.org/xml/5.0/xsd/docbook.xsd"
  xmlns="http://docbook.org/ns/docbook" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns:xs="http://www.w3.org/2001/XMLSchema" xmlns:xl="http://www.w3.org/1999/xlink"
  xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xhtml="http://www.w3.org/1999/xhtml"
  xmlns:svg="http://www.w3.org/2000/svg" xmlns:mth="http://www.w3.org/1998/Math/MathML"
  xmlns:db="http://docbook.org/ns/docbook" xml:id="data_admin">
  <title><?oxy_comment_start author="cecilia" timestamp="20161010T104310+0200" comment="This seciton needs a full editorial review and restructure."?>Data<?oxy_comment_end?>
    <?oxy_comment_start author="cecilia" timestamp="20161010T094352+0200" comment="Removed data browser section for 2.25, functionality removed from system." flag="done"?>Administration<?oxy_comment_end?></title>
  <para>The data administration module provides a range of functions to ensure that the data stored
    in the DHIS2 database is integral and that the database performance is optimised. These
    functions should be executed on a regular basis by a data administrator to ensure that the
    quality of the data stored is optimal. </para>
  <section xml:id="dataAdmin_dataIntegrity">
    <title>Data integrity</title>
    <para>DHIS2 can perform a wide range of data integrity checks on the data contained in the
      database. Identifying and correcting data integrity issues is extremely important for ensuring
      that the data used for analysis purposes is valid. Each of the data integrity checks that are
      performed by the system will be described, along with general procedures that can be performed
      to resolve these issues. </para>
    <section>
      <title>Data elements without data set</title>
      <para>Each data element must be assigned to a data set. Values for data elements will not be
        able to be entered into the system if a data element is not assigned to a data set. Choose
        Maintenance-&gt;Datasets-&gt;Edit from the main menu and then add the &quot;orphaned&quot;
        data element to the appropriate data set. </para>
    </section>
    <section>
      <title>Data elements without groups</title>
      <para>Some Data Elements have been allocated to several Data Element Groups. This is currently
        not allowed, because it will result in duplication of linked data records in the analytics
        record sets that provide aggregated data. Go to Maintenance -&gt; Data Element Groups to
        review each Data Element identified and remove the incorrect Group allocations.</para>
    </section>
    <section>
      <title>Data elements violating exclusive group sets</title>
      <para> Some data elements have been allocated to several data element groups that are members
        of the same data element group set. All group sets in DHIS2 are defined as exclusive, which
        means that a data element can <emphasis>only</emphasis> be allocated to
          <emphasis>one</emphasis> data element group within that group set. Go to Maintenance -&gt;
        Data elements and indicators -&gt;Data element groups to review each data element identified
        in the integrity check. Either remove the data element from all groups except the one that
        it should be allocated to, or see if one of the groups should be placed in a different group
        set. </para>
    </section>
    <section>
      <title>Data elements in data set but not in form or sections</title>
      <para>Data elements have been assigned to a data set, but have not been assigned to any
        sections of the data set forms. All data sets which use section forms, should generally have
        all data elements in the data set assigned to exactly one section of the dataset. </para>
    </section>
    <section>
      <title>Data elements assigned to data sets with different period types</title>
      <para>Data elements should not be assigned to two separate data sets whose period types
        differ. The recommended approach would be to create two separate data elements (for instance
        a monthly and yearly data element) and assign these to respective datasets. </para>
    </section>
    <section>
      <title>Data sets not assigned to organisation units</title>
      <para>All data sets should be assigned to at least one organisation unit. </para>
    </section>
    <section>
      <title>Sections with invalid category combinations </title>
      <para>Data sets which use section forms should only have a single category combination within
        each section. This violation could result from assigning a data element to a section, but
        then changing the category combination of this data element at a later point in time.
      </para>
    </section>
    <section>
      <title>Indicators with identical formulas</title>
      <para>Although this rule will not affect data quality, it generally does not make sense to
        have two indicators with the exact same definition. Review the identified indicators and
        their formulas and delete or modify any indicator that appears to be the duplicate.</para>
    </section>
    <section>
      <title>Indicators without groups</title>
      <para>All data elements and indicators must be assigned to at least one group, so these
        Indicators need to be allocated to their correct Data Element and Indicator Group. From the
        main menu, go to Data elements/Indicators -&gt; Indicator Groups, and allocate each of the
        `Orphaned` indicators to its correct group.</para>
    </section>
    <section>
      <title>Invalid indicator numerators</title>
      <para>Violations of this rule may be caused by an incorrect reference to a deleted or modified
        data element. Review the indicator and make corrections to the numerator definition. </para>
    </section>
    <section>
      <title>Invalid indicator denominators</title>
      <para>Violations of this rule may be caused by an incorrect reference to a deleted or modified
        data element. Review the indicator and make corrections to the denominator definition.
      </para>
    </section>
    <section>
      <title>Indicators violating exclusive group sets</title>
      <para> Some indicators have been allocated to several indicator groups that are members of the
        same indicator group set. All group sets in DHIS2 are defined as exclusive, which means that
        an indicator can <emphasis>only</emphasis> be allocated to <emphasis>one</emphasis>
        indicator group within that group set. Go to Maintenance -&gt; Data elements and indicators
        -&gt;Indicator groups to review each indicator identified in the integrity check. Either
        remove the indicator from all groups except the one that it should be allocated to, or see
        if one of the groups should be placed in a different group set. </para>
    </section>
    <section>
      <title>Duplicate periods</title>
      <para>If periods have been imported from external applications, it may be possible that some
        periods will be duplicated. If you have any periods which appear to be duplicated here, you
        will need to resolve these directly in the DHIS2 database. All data which has been assigned
        to the duplicated period, should be moved to the correct period, and the duplicate period
        should be removed. </para>
    </section>
    <section>
      <title> Organisation units with cyclic references</title>
      <para>Organisation units cannot be both parent and children of each other, directly nor
        indirectly. If this situation occurs, you will need to resolve the cyclic reference directly
        in the DHIS2 database in the &quot;organisation unit&quot; table, by reassigning the
        &quot;parentid&quot; field of the organisation units. </para>
    </section>
    <section>
      <title>Orphaned organisation units</title>
      <para>All organisation units must exist within the organisation unit hierarchy. Go to
        Organisation- units &gt;Hierarchy Operations and move the offending organisation unit into
        the proper position in the hierarchy. </para>
    </section>
    <section>
      <title>Organisation units without groups</title>
      <para>All organisation units <emphasis>must</emphasis> be allocated to at least
          <emphasis>one</emphasis> group. The problem might either be that you have not defined any
        compulsory OrgUnit Group Set at all, or that there are violations of the compulsory rule for
        some OrgUnits . NOTE: If you have defined no compulsory OrgUnit Group Sets, then you must
        first define them by going to Organisation units-&gt;Organisation unit group sets and define
        at least one compulsory Group Set (the group set &apos;Type&apos; are nearly universally
        relevant). If you have the relevant group sets, go to Maintenance -&gt; OrgUnit Groups to
        review each OrgUnit identified and add the relevant Group allocation.</para>
    </section>
    <section>
      <title>Organisation units violating compulsory group sets</title>
      <para>These organisation units have not been assigned to the any organisation unit group
        within one of the <emphasis>compulsory</emphasis> organisation unit group sets. When a group
        set is defined as compulsory, it means that an organisation unit must be allocated to at
        least one organisation unit group within that group set. For instance, all organisation
        units must belong to one of the groups in the &apos;Type&apos; group set. It might belong to
        the `Hospital` or the `Clinic` or any other &apos;type&apos; group - but it must belong to
        exactly one of them. Go to Organisation units-&gt;Organisation unit groups to review each
        organisation unit identified in the integrity check. Allocate all organisation units to
        exactly one compulsory group. </para>
    </section>
    <section>
      <title>Organisation units violating exclusive group sets</title>
      <para>Some organisation units have been allocated to several organisation unit groups that are
        members of the same organisation unit group set. All group sets in DHIS2 are defined as
        exclusive, which means that an organisation unit can <emphasis>only</emphasis> be allocated
        to <emphasis>one</emphasis> organisation unit group within that Group Set. For instance, one
        organisation unit cannot normally belong to the both the &apos;Hospital&apos; and
        &apos;Clinic&apos; groups , but rather to only to one of them. Go to Organisation
        unit-&gt;Organisation unit groups to review each organisation unit identified in the
        integrity check. Remove the organisation units from all groups except the one that it should
        be allocated to.</para>
    </section>
    <section>
      <title> Organisation unit groups without group sets</title>
      <para>The organisation unit groups listed here have not been allocated to a group set. Go to
        Maintenance-&gt;Organisation unit-&gt;Organisation unit group sets and allocate the
        Organisation unit group to the appropriate group set. </para>
    </section>
    <section>
      <title>Validation rules without groups</title>
      <para>All validation rules must be assigned to a group. Go to <command>Data
          quality-&gt;Validation rule group</command> and assign the offending validation rule to a
        group. </para>
    </section>
    <section>
      <title>Invalid validation rule left side expressions</title>
      <para>An error exists in the left-side validation rule definition. Go to <command>Data
          quality-&gt;Validation rule</command> and click the &quot;Edit&quot; icon on the offending
        rule. Press &quot;Edit left side&quot; and make the corrections that are required. </para>
    </section>
    <section>
      <title>Invalid validation rule right side expressions</title>
      <para>An error exists in the left-side validation rule definition. Go to <command>Data
          quality-&gt;Validation rule</command> and click the &quot;Edit&quot; icon on the offending
        rule. Press &quot;Edit right side&quot; and make the corrections that are required.</para>
    </section>
  </section>
  <section xml:id="data_admin_maintenance">
    <title>Maintenance</title>
    <table frame="all">
      <title>Data maintenance functions in the Data Administration app</title>
      <tgroup cols="2">
        <colspec colname="c1" colnum="1" colwidth="1.0*"/>
        <colspec colname="c2" colnum="2" colwidth="1.0*"/>
        <thead>
          <row>
            <entry>
              <para>Function</para>
            </entry>
            <entry>
              <para>Description</para>
            </entry>
          </row>
        </thead>
        <tbody>
          <row>
            <entry>
              <para>Clear analytics tables</para>
            </entry>
            <entry>
              <para>Completely empties the analytics tables. These tables are used to generate
                aggregate data for the pivot tables, GIS and reports. </para>
            </entry>
          </row>
          <row>
            <entry>
              <para>Remove zero data values</para>
            </entry>
            <entry>
              <para>Removes zero data values from the database. Values registered for data elements
                with aggregation operator average is not removed, as such values will be significant
                when aggregating the data, contrary to values registered for data elements with
                aggregation operator sum. </para>
              <para>Reducing the number of data values will improve system performance.</para>
            </entry>
          </row>
          <row>
            <entry>
              <para>Permanently remove soft deleted data values</para>
            </entry>
            <entry>
              <para>When a data value is deleted in DHIS2, the system will mark the corresponding
                database row as deleted, and not actually delete the row. </para>
              <para>Running this maintenance function will physically remove these data value rows
                from the database.</para>
            </entry>
          </row>
          <row>
            <entry>
              <para>Prune periods</para>
            </entry>
            <entry>
              <para>Removes all periods which have no registered data values. Reducing the number of
                periods will improve system performance.</para>
            </entry>
          </row>
          <row>
            <entry>
              <para>Remove expired invitations</para>
            </entry>
            <entry>
              <para>Will delete users which represent user account invitations that now have gone
                past their expiry date.</para>
            </entry>
          </row>
          <row>
            <entry>
              <para>Drop SQL views</para>
            </entry>
            <entry>
              <para>DHIS2 lets you set up and manage SQL views as system objects with corresponding
                database SQL views.</para>
              <para>Running this maintenance function will drop underlying SQL views for all system
                views. Use the <emphasis role="bold">Create SQL views</emphasis> function to
                recreate these SQL views.</para>
            </entry>
          </row>
          <row>
            <entry>
              <para>Create SQL views</para>
            </entry>
            <entry>
              <para>Recreates all SQL views in the database.</para>
            </entry>
          </row>
          <row>
            <entry>
              <para>Update category option combinations</para>
            </entry>
            <entry>
              <para>Rebuilds the category option combinations. This may be required after altering
                the category options which belong to a given category. </para>
            </entry>
          </row>
          <row>
            <entry>
              <para>Update organisation unit paths</para>
            </entry>
            <entry>
              <para>The organisation unit table in the DHIS2 database has a column "path" which
                contains a concatenated string of all ancestors in the hierarchy for each
                organisation unit. </para>
              <para>Running this maintenance function will update and ensure that these values are
                in sync with the current organisation unit hierarchy. This column is managed by
                DHIS2, but a manual update might be useful when doing data loading directly in the
                database.</para>
            </entry>
          </row>
          <row>
            <entry>
              <para>Clear application cache</para>
            </entry>
            <entry>
              <para>Clears the system cache.</para>
            </entry>
          </row>
          <row>
            <entry>
              <para>Reload apps</para>
            </entry>
            <entry>
              <para>Manually reloads and detects installed DHIS2 apps.</para>
              <para>The installed apps are also detected when the system starts and when installing
                or uninstall apps.</para>
            </entry>
          </row>
        </tbody>
      </tgroup>
    </table>
  </section>
  <section xml:id="dataAdmin_resourceTables">
    <title>Resource tables</title>
    <para>Resource tables are supporting tables that are used during analysis of data. One would
      typically join the contents of these tables with the data value table when doing queries from
      third-party applications like Microsoft Excel. They are also used extensively by the analysis
      modules of DHIS2. Regeneration of the resource tables should only be done once all data
      integrity issues are resolved. The resource tables are also generated automatically, every
      time the analytics process is run by the system. </para>
    <itemizedlist>
      <listitem>
        <para>Organisation unit structure (_orgunitstructure)</para>
        <para>This table should be regenerated any time there have been any changes made to the
          organisational unit hierarchy. This table provides information about the organisation unit
          hierarchy. It has one row for each organisation unit, one column for each organisation
          unit level and the organisation unit identifiers for all parents in the lineage as
          values.</para>
      </listitem>
      <listitem>
        <para>Data element group set structure (_dataelementgroupsetstructure)</para>
        <para>This table provides information about which data elements are members of which data
          element group sets. The table has one row for each data element, one column for each data
          element group set and the names of the data element group as values.</para>
      </listitem>
      <listitem>
        <para>Indicator group set structure (_indicatorgroupsetstructure)</para>
        <para>This table provides information about which indicators are members of which indicator
          group sets. The table has one row for each indicator, one column for each indicator group
          set and the names of the indicator group as values.</para>
      </listitem>
      <listitem>
        <para>Organisation unit group set structure (_organisationunitgroupsetstructure)</para>
        <para>This table provides information about which organisation units are members of which
          organisation unit group sets. The table has one row for each organisation unit, one column
          for each organisation unit group set and the names of the organisation unit groups as
          values.</para>
      </listitem>
      <listitem>
        <para>Category structure (_categorystructure)</para>
        <para>This table provides information about which data elements are members of which
          categories. The table has one row for each data element, one column for each category and
          the names of the category options as values.</para>
      </listitem>
      <listitem>
        <para>Data element category option combo name (_categoryoptioncomboname)</para>
        <para>This table should be regenerated any time there have been changes made to the category
          combination names. It contains readable names for the various combinations of
          categories.</para>
      </listitem>
      <listitem>
        <para>Data element structure (_dataelementstructure)</para>
        <para>This table provides information about all data elements and which period type
          (frequency) they capture data at. The period type is determined through the data set
          membership and hence relies on data elements to be member of data sets with similar period
          types to have a defined behavior.</para>
      </listitem>
      <listitem>
        <para>Period structure (_dataperiodstructure)</para>
        <para>This table provides information about all periods and which period type they are
          associated with. For each period type with lower frequency than itself, it contains
          information about which period it will fall within.</para>
      </listitem>
      <listitem>
        <para>Data element category option combinations (_dataelementcategoryoptioncombo)</para>
        <para>This table provides a mapping between data elements and all possible category option
          combinations. </para>
      </listitem>
    </itemizedlist>
  </section>
  <section xml:id="dataAdmin_local_management">
    <title>Locale Management</title>
    <para>It is possible to create custom locales in DHIS2. In addition to the locales available
      through the system, you might want to add a custom locale such as &quot;English&quot; and
      &quot;Zambia&quot; to the system. This would allow you to translate metadata objects to local
      languages, or to account for slight variants between countries which use a common metadata
      definition. </para>
    <screenshot>
      <mediaobject>
        <imageobject>
          <imagedata width="30%" align="center"
            fileref="resources/images/maintainence/locale_management.png"/>
        </imageobject>
      </mediaobject>
    </screenshot>
    <para>The locale is composed of a language along with a country. Select the desired values and
      press &quot;Add&quot;. This custom locale will now be available as one of the translation
      locales in the system. </para>
  </section>
  <section xml:id="dataAdmin_sqlView">
    <title>SQL View</title>
    <para>The SQL View functionality of DHIS2 will store the SQL view definition internally, and
      then materialize the view when requested. </para>
    <para>Database administrators must be careful about creating database views directly in the DHIS
      2 database. For instance, when the resource tables are generated, all of them will first be
      dropped and then re-created. If any SQL views depend on these tables, an integrity violation
      exception will be thrown and the process will be aborted.</para>
    <para>The SQL views are dropped in reverse alphabetical order based on their names in DHIS2, and
      created in regular alphabetical order. This allows you to have dependencies between SQL views,
      given that views only depend on other views which come earlier in the alphabetical order. For
      instance, &quot;ViewB&quot; can safely depend on &quot;ViewA&quot;. Otherwise, having views
      depending on other view result in an integrity violation error.</para>
    <section>
      <title>Creating a new SQL view</title>
      <para>To create a new SQL view, click <emphasis role="bold">Apps</emphasis> > <emphasis
          role="bold">Data administration</emphasis> &gt;<emphasis role="bold">SQL view</emphasis>
        and click <emphasis role="bold">Add new</emphasis>. </para>
      <screenshot>
        <mediaobject>
          <imageobject>
            <imagedata width="80%" align="center"
              fileref="resources/images/maintainence/create_sql_view.PNG"/>
          </imageobject>
        </mediaobject>
      </screenshot>
      <para>The &quot;Name&quot; attribute of the SQL view will be used to determine the name of the
        table that DHIS2 will create when the view is materialized by the user. The
        &quot;Description&quot; attribute allows one to provide some descriptive text about what the
        SQL view actually does. Finally, the &quot;SQL statement&quot; should contain the SQL view
        definition. Only SQL &quot;SELECT&quot; statements are allowed and certain sensitive tables
        (i.e. user information) are not accessible Press &quot;Save&quot; to store the SQL view
        definition.</para>
    </section>
    <section>
      <title>SQL View management</title>
      <para>In order to utilize the SQL views, simply click the view and from the context menu,
        choose &quot;Execute query&quot;. Once the process is completed, you will be informed that a
        table has been created. The name of the table will be provided, and is composed from the
        &quot;Description&quot; attribute provided in the SQL view definition. Once the view has
        been generated, you can view it by clicking the view again, and selecting "Show SQL View". </para>
      <tip>
        <para>If you have a view which depends on another view, you should be careful about how the
          views are named. When analytics is run on the DHIS2 server, all views must be dropped, and
          are recreated. When analytics starts, the views are dropped in alphabetical order, and
          then recreated in reverse alphabetical order. Thus, if view A depends on view B, it must
          appear before view B in alphabetical order. If it appears after view B in alphabetical
          order, analytics may fail, as the view with dependencies will not be dropped in the
          correct order.</para>
      </tip>
    </section>
  </section>
  <section xml:id="dataAdmin_duplicateDataElimination">
    <title>Duplicate data elimination</title>
    <para>This function is useful when data has been entered mistakenly for two data elements which
      represents the same phenomena.</para>
    <para>Start by selecting the data element to eliminate from the list and click confirm. Then
      select the data element to keep and click confirm again. Finally, verify the selection and
      click merge.</para>
    <para>In the situation where data exists for the data element to eliminate and not for the one
      to keep, the data will be moved to the one to keep. When data exists for both data elements,
      the data which was updated last will be used. When data exists only for the one to keep, no
      action will be taken. The data element to eliminate will eventually be deleted, except when it
      is a multidimensional data element and has other data registered.</para>
  </section>
  <section xml:id="dataAdmin_dataStatistics">
    <title>Data statistics</title>
    <para>The data statistics module provides an overview of the number of objects stored in the
      DHIS2 database. </para>
    <screenshot>
      <mediaobject>
        <imageobject>
          <imagedata width="60%" fileref="resources/images/maintainence/data_stats.png" format="PNG"
            align="center"/>
        </imageobject>
      </mediaobject>
    </screenshot>
    <para>The total number of each type of object is presented in a series of tables with summary
      statistics of each object. </para>
  </section>
  <section xml:id="dataAdmin_lockException">
    <title>Lock exceptions</title>
    <para>Lock exceptions provide fine-grained control over exemption from a locked data set. After
      the expiry of the data set, data entry will be denied by default, unless an exception has been
      granted through the Lock exception interface. To enable a lock exception, select the desired
      organization units, data sets, and time period and press &quot;Add&quot;. By granting a lock
      exception, data entry will be enabled even after the expiry period of the data set has passed. </para>
    <screenshot>
      <mediaobject>
        <imageobject>
          <imagedata width="50%" align="center"
            fileref="resources/images/maintainence/create_lock_exception.png"/>
        </imageobject>
      </mediaobject>
    </screenshot>
    <para>In the example above, a data lock exception would be created for &quot;ab Abundant Life
      Organization&quot; and &quot;ab Seventh Day Hospital&quot; for the &quot;Care and
      Support&quot; dataset for &quot;February 2012&quot;. </para>
  </section>
  <section xml:id="dataAdmin_minMaxValueGeneration">
    <title>Min-Max Value Generation</title>
    <para>This administrative function can be used to generate min-max values, which are used as
      part of the data quality and validation process for specific organization units and data sets.
      Simply select the dataset from the left hand frame, and then select the required organisation
      units to generate the min-max values for from the organisational units selector on the right.
      Press the &quot;Generate&quot; button to generate or regenerate all min-max values. Press
      &quot;Remove&quot; to remove all min-max values which are currently stored in the database. </para>
    <para>
      <screenshot>
        <mediaobject>
          <imageobject>
            <imagedata width="80%" align="center"
              fileref="resources/images/maintainence/min_max_value_generation.PNG"/>
          </imageobject>
        </mediaobject>
      </screenshot>
    </para>
  </section>
  <section xml:id="dataAdmin_cacheStatistics">
    <title>Cache Statistics </title>
    <para>This option is for system administrators only to use. The cache statistics shows the
      status of the application level cache. The application level cache refers to the objects and
      query results that the application is caching in order to speed up performance. If the
      database has been modified directly the application cache needs to be cleared for it to take
      effect.</para>
  </section>
  <section xml:id="dataAdmin_scheduling">
    <title>Scheduling</title>
    <para>The analytics, resource tables, data sync, metadata sync and data mart can be
      automatically scheduled to run on regular intervals. Simply select the aggregation period
      types, organisation unit group set aggregation level, and strategy to configure how the
      scheduled job should run. If you are using surveillance rules, you can choose to run them
      &quot;All daily&quot; by selecting this option.</para>
    <para>Pressing &quot;Start&quot; will enable the scheduled job to run at a pre-determined time
      (always at midnight based on the server time).</para>
    <screenshot>
      <mediaobject>
        <imageobject>
          <imagedata width="70%" align="center"
            fileref="resources/images/maintainence/scheduling_management.png"/>
        </imageobject>
      </mediaobject>
    </screenshot>
    <para>Starting 2.24 you can also schedule metadata synchronization on regular intervals. Simply
      select &quot;Enabled&quot; from the drop-down, select the time-period during which you want to
      run the task. Pressing &quot;Start&quot; will enable the scheduled job to run at that specific
      time selected.</para>
    <screenshot>
      <mediaobject>
        <imageobject>
          <imagedata width="60%" align="center"
            fileref="resources/images/maintainence/metadata_synchronization.png"/>
        </imageobject>
      </mediaobject>
    </screenshot>
    <para>As depicted in the screenshot, you can select the time period as daily, weekly, monthly or
      yearly.</para>
    <itemizedlist>
      <listitem>
        <para>Daily: On selecting this checkbox, you will need to select the time at which it needs
          to run daily.</para>
      </listitem>
      <listitem>
        <para>Weekly: On selecting this checkbox, you need to select the day of the week and time on
          that day on which it needs to run.</para>
      </listitem>
      <listitem>
        <para>Monthly: On selecting this checkbox, you need to select a day of the week, say Every
          1st Sunday, Every 2nd Saturday, etc. and time on that day on which it needs to run.</para>
      </listitem>
      <listitem>
        <para>Yearly: On Selecting this check box, you need to select the month, specific day of the
          month and time on that day on which it needs to run.</para>
      </listitem>
    </itemizedlist>
    <para>There is also the capability for running the meta data synchronization immediately. Using
        &quot;<emphasis role="bold">Sync Now</emphasis>&quot; button you can run the meta data
      synchronization task immediately even if the scheduler is scheduled to run at specific time or
      not.</para>
    <itemizedlist>
      <listitem>
        <para>If the scheduler is already enabled, you will see the &quot;Sync Now&quot; button on
          the page itself.</para>
      </listitem>
      <listitem>
        <para>If the scheduler is not enabled, simply select &quot;Enabled&quot; from the drop-down
          for Metadata Synchronization and click &quot;Sync Now&quot; button.</para>
      </listitem>
    </itemizedlist>
  </section>
  <section xml:id="dataAdmin_dataSync">
    <title>Data synchronization</title>
    <para>DHIS2 provides a feature for synchronizing data being captured on the local instance with
      a another, remote instance of DHIS2. This can be useful e.g. when you have deployed multiple
      stand-alone instances of DHIS2 which are required to submit data values to a central DHIS2
      instance. Till now only aggregate data was being synced. Starting from 2.24 even non anonymous
      events data (line list) will also be synced.</para>
    <para>These are the steps to enable data synchronization:<itemizedlist>
        <listitem>
          <para>Go to Settings &gt; Synchronization, enter the remote server URL, username and
            password and click Save. You can test your settings by clicking on the &quot;Test
            settings&quot; link.</para>
        </listitem>
        <listitem>
          <para>Go to Data administration &gt; Scheduling. Under Data synchronization set strategy
            to Enabled, and click Start.</para>
        </listitem>
      </itemizedlist></para>
    <para>Some aspects of the data synchronization feature to be aware of:<itemizedlist>
        <listitem>
          <para>The local DHIS2 instance will store the password of the user account on the remote
            instance encrypted in the local database. The remote account is used for authentication
            when transferring data. For security purposes make sure you set the
            &quot;enryption.password&quot; configuration parameter in hibernate.properties to a
            strong password.</para>
        </listitem>
        <listitem>
          <para>Deploying the remote server on SSL/HTTPS is strongly recommended as the username and
            password are sent in clear text using basic authentication and could be intercepted by
            an attacker.</para>
        </listitem>
        <listitem>
          <para>The data synchronization uses the UID property of data elements, category option
            combos and organisation units to match the meta-data. Hence the synchronization is
            dependent on these three meta-data objects being harmonized on the local and remote
            instance in order to work appropriately.</para>
        </listitem>
        <listitem>
          <para>The very first time DHIS2 attempts to synchronize data the system will include data
            entered during the last three days. For the subsequent attempts the system will store
            the time of the last successful data synchronization and only include data saved or
            edited since that time. A synchronization job is considered successful only if data was
            submitted, authenticated and saved successfully on the remote server,.</para>
        </listitem>
        <listitem>
          <para>The system will attempt a synchronization every minute. If the local server does not
            have a working Internet connection at the time, the synchronization will be silenly
            aborted and re-attempted after a minute.</para>
        </listitem>
        <listitem>
          <para>You can see the time of last successful synchronization with remote server in the
            scheduling screen next to the &quot;Last success&quot; label.</para>
        </listitem>
      </itemizedlist></para>
  </section>
  <section xml:id="dataAdmin_metaDataSync">
    <title>Metadata Synchronization
      <?oxy_comment_start author="cecilia" timestamp="20160704T115331+0200" comment="2.24: Removed xml:id tag Metadata Synchronization
Linking between files doesn&apos;t work."?>Scheduling<?oxy_comment_end?></title>
    <para>DHIS2 provides a feature for synchronizing meta data from a remote instance to a local
      instance of DHIS2. This can be useful when you have deployed multiple stand-alone instances of
      DHIS2 and you need to create meta data in all the local instances similar to the central DHIS2
      instance.</para>
    <para>These are the steps to enable meta data synchronization:</para>
    <itemizedlist>
      <listitem>
        <para>Go to Settings &gt; Synchronization, enter the remote server URL, username and
          password and click Save.</para>
      </listitem>
      <listitem>
        <para>Go to Metadata administration &gt; Scheduling. Under Metadata synchronization set
          strategy to Enabled, select the time-period and click Start.</para>
      </listitem>
    </itemizedlist>
    <para>Some aspects of the meta data synchronization feature to be aware of:</para>
    <itemizedlist>
      <listitem>
        <para>The local DHIS2 instance will store the password of the user account of the remote
          instance in its database. The remote user account is used for authentication when
          transferring/downloading data. For security purposes make sure you set the
          &quot;encryption.password&quot; configuration parameter in hibernate.properties to a
          strong password.</para>
      </listitem>
      <listitem>
        <para>Deploying the remote server on SSL/HTTPS is strongly recommended as the username and
          password are sent in clear text using basic authentication and could be intercepted by an
          attacker.</para>
      </listitem>
      <listitem>
        <para>Also ensure that the remote user is not having ALL authority, instead simply create a
          user with F_METADATA_MANAGE authority so that even if these details are intercepted by a
          hacker, one cannot have full control of the remote system.</para>
      </listitem>
      <listitem>
        <para>The meta data synchronization relies on the underlying import layer. Each meta data
          version is an export of meta data between two given timestamps. Each sync of meta data
          version is an attempt to import that meta data snapshot into the local instance. The sync
          of versions is incremental. The local instance will try to download the meta data versions
          from the central instance one after the other. Failure to sync a specific meta data
          version will not let the sync proceed to further versions. In case of failures,
          appropriate changes must be made to meta data at central to ensure that the error gets
          resolved. Metadata configuration is critical and the configurator should be careful while
          rolling out the updates to the production. It&apos;s always recommended to have staging
          environments in place to ensure the sanity of the meta data versions and their impact
          thereafter. The local instance will sync the meta data from first version so that harmony
          is maintained and local and central instance will work appropriately.</para>
      </listitem>
      <listitem>
        <para>The system will attempt a synchronization at the scheduled time. If the local or
          remote server does not have a working Internet connection at the time, the synchronization
          will be aborted and re-attempted after as per the retry count as mentioned in the
          dhis.conf file.</para>
      </listitem>
      <listitem>
        <para>You can see the time of last successful synchronization with remote server in the
          scheduling screen next to the &quot;Last success&quot; label.</para>
      </listitem>
    </itemizedlist>
  </section>
</chapter>
